{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0084eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "SEED = 456\n",
    "#TEST = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train_restaurants.csv\", index_col = [0])\n",
    "X_test = pd.read_csv(\"X_test_restaurants.csv\", index_col = [0])\n",
    "y_train = pd.read_csv(\"y_train_restaurants.csv\", index_col = [0])\n",
    "y_test = pd.read_csv(\"y_test_restaurants.csv\", index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace680ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b56db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d74c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[\"GRADE\"].value_counts()\n",
    "\n",
    "# B and C unbalanced - generate synthetic samples with SMOTE \n",
    "# (risky because would need to generate more instnaces than exist currectly)\n",
    "# OR\n",
    "# undersample A (down to 4000 - 4500)\n",
    "\n",
    "\n",
    "# decision trees (random forest - normal data)\n",
    "# penalized SVM (normal data)\n",
    "# THEN:\n",
    "# SVM (over/undersampled data)\n",
    "# naive bayes (oversampled data)\n",
    "\n",
    "\n",
    "# eval metrics:\n",
    "# ROC and AUC\n",
    "# F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sub = X_train.drop(\"VIOLATION DESCRIPTION\", axis = 1)\n",
    "X_test_sub = X_test.drop(\"VIOLATION DESCRIPTION\", axis = 1)\n",
    "\n",
    "cols = ['BORO', 'CUISINE DESCRIPTION','INSPECTION TYPE', 'INSPECTION PURPOSE']\n",
    "X_train_sub = pd.get_dummies(X_train_sub, columns = cols)\n",
    "X_test_sub = pd.get_dummies(X_test_sub, columns = cols)\n",
    "\n",
    "X_train_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a026735",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2580d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(y_train[\"GRADE\"].value_counts())\n",
    "\n",
    "y_train[\"GRADE\"].value_counts().values/len(X_train_sub)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a28403b",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Key Assumption - ...\n",
    "\n",
    "- Decision trees good for unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "kfold = KFold(n_splits = 5)\n",
    "parameters = {'class_weight':[None, \"balanced\", {\"A\":1, \"B\":3, \"C\":3}], 'min_samples_leaf':[100, 200, 300]}\n",
    "rf = RandomForestClassifier(max_depth = 5, random_state = SEED)\n",
    "best_rf = GridSearchCV(rf, parameters, cv = kfold)\n",
    "best_rf.fit(X_train_sub, y_train[\"GRADE\"])\n",
    "best_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = best_rf.predict(X_test_sub)\n",
    "f1_score(y_test[\"GRADE\"], rf_pred, average = \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ca56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_sub.info()#.select_dtypes(include = [\"int64\"])\n",
    "#type(best_rf_pred_num)\n",
    "#type(grades)\n",
    "#best_rf_pred_num.shape\n",
    "\n",
    "X_train_sub[\"YEAR\"].value_counts() #(2015 (only 2) - 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f86c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted = pd.DataFrame(best_rf_pred, columns = best_rf.classes_)\n",
    "#display(predicted)\n",
    "#col_max = predicted.max(axis = 1)\n",
    "#for col in predicted:\n",
    "    #predicted.loc[predicted[col] == col_max, col] = col\n",
    "\n",
    "#predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686781cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in predicted.index:\n",
    "    #print(col)\n",
    "    \n",
    "#predicted[\"A\"].astype(\"str\") + predicted[\"B\"].astype(\"str\") + predicted[\"C\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6129d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_rf_pred_num = pd.Series(best_rf_pred)\n",
    "grades = y_test[\"GRADE\"].copy()\n",
    "\n",
    "#for grade, value in {'A':'1', 'B':'2', 'C':'3'}.items():\n",
    "    #best_rf_pred_num = best_rf_pred_num.replace(grade, value)\n",
    "    #grades = grades.replace(grade, value)\n",
    "\n",
    "#best_rf_pred_num = best_rf_pred_num.astype('int32')\n",
    "#grades = grades.astype('int32')\n",
    "\n",
    "# lol all this code was a waste of time\n",
    "    \n",
    "best_rf_pred = best_rf.predict_proba(X_test_sub)\n",
    "rf_auc = roc_auc_score(grades, best_rf_pred, multi_class = \"ovr\", average = \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa5095",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e7f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "y_onehot_test = label_binarizer.transform(y_test)\n",
    "#y_onehot_test.shape\n",
    "\n",
    "def plot_roc_curve(class_of_interest, prediction):\n",
    "    class_id = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]\n",
    "    \n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test[:, class_id],\n",
    "        prediction[:, class_id],\n",
    "        name = f\"{class_of_interest} vs Other Classes\",\n",
    "        color = \"dodgerblue\"\n",
    "    )\n",
    "    plt.axis(\"square\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"One-vs-Rest ROC curves:\\n{} vs Other Classes\".format(class_of_interest))\n",
    "    plt.plot([0, 1], [0, 1], linestyle = '--', lw = 2, color = 'black', label = 'Guideline')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_roc_curve(\"A\", best_rf_pred)\n",
    "plot_roc_curve(\"B\", best_rf_pred)\n",
    "plot_roc_curve(\"C\", best_rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200be16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_rf.estimators_[0]\n",
    "## not possible with grid search cv\n",
    "#y_train[\"GRADE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import tree\n",
    "#i = 99\n",
    "\n",
    "#fn = X_train_sub.columns\n",
    "#cn = y_train.GRADE.unique()\n",
    "#fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (3, 3), dpi = 1000)\n",
    "#tree.plot_tree(best_rf.estimators_[i],\n",
    "               #feature_names = fn, \n",
    "               #class_names = cn,\n",
    "               #filled = True);\n",
    "#fig.savefig('RF_Tree100.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748adc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model f1 score\n",
    "#f1_score(y_test[\"GRADE\"], best_rf.predict(X_test_sub), average = \"weighted\")\n",
    "\n",
    "# add precision and recall ()\n",
    "# compare models at end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa20556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#knjwer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974e3ce",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Key Assumption - conditional independence of x's\n",
    "\"Thus, if we know that warm weather improves our sales process, then this weather effect is conditionally independent from the age of our customers if this weather effect does not increase or decrease if the customer is younger or older.\"\n",
    "- effect of x1 on y constant with changes in x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b3afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e35d2ec",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69259019",
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_train = X_train[[\"BORO\", \"CUISINE DESCRIPTION\", \"VIOLATION DESCRIPTION\"]]\n",
    "violations_test = X_test[[\"BORO\", \"CUISINE DESCRIPTION\", \"VIOLATION DESCRIPTION\"]]\n",
    "\n",
    "violations_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be6272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def replace_degree(text):\n",
    "    return text.replace(\"°\", \"\")\n",
    "\n",
    "def split_text(text):\n",
    "    return text.split(\" \")\n",
    "\n",
    "p = list(punctuation)\n",
    "p.pop(12)\n",
    "p = p + ['°']\n",
    "\n",
    "def strip_punctuation(text, p = p):\n",
    "    for x in p:\n",
    "        text = text.replace(x, \"\")\n",
    "    return text\n",
    "\n",
    "STOP_WORDS = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stop_words(text_list):\n",
    "    clean_text = []    \n",
    "    for word in text_list:\n",
    "        if word not in STOP_WORDS:\n",
    "            clean_text.append(word)\n",
    "    return clean_text\n",
    "\n",
    "def combine_tokens(text_list):\n",
    "    new_string = \" \".join(text_list)\n",
    "    return new_string\n",
    "\n",
    "\n",
    "violations_train[\"VIOLATIONS DESCRIPTION\"] = violations_train[\"VIOLATION DESCRIPTION\"].apply(replace_degree)\n",
    "violations_train[\"VIOLATIONS\"] = violations_train[\"VIOLATION DESCRIPTION\"].apply(make_lower)\n",
    "violations_train[\"VIOLATIONS\"] = violations_train[\"VIOLATIONS\"].apply(strip_punctuation)\n",
    "violations_train[\"VIOLATIONS\"] = violations_train[\"VIOLATIONS\"].apply(split_text)\n",
    "violations_train[\"CLEAN VIOLATIONS\"] = violations_train[\"VIOLATIONS\"].apply(remove_stop_words)\n",
    "violations_train[\"PROCESSED VIOLATIONS\"] = violations_train[\"CLEAN VIOLATIONS\"].apply(combine_tokens)\n",
    "violations_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ad75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_train[\"BORO\"].value_counts()\n",
    "# split and analyze by borough/boro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761361fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(violations_train[\"PROCESSED VIOLATIONS\"])\n",
    "matrix = pd.DataFrame(X.toarray(), columns = vec.get_feature_names_out(), index = violations_train.index)\n",
    "matrix = matrix.iloc[:, (np.where(matrix.sum() >= 100)[0].tolist())]\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd85db",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.sum().sort_values(ascending = False).head(30)\n",
    "\n",
    "# words to drop: food, non, andor, may, properly, improperly, unacceptable, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d5fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = matrix.drop([\"food\", \"non\", \"andor\", \"may\", \"properly\", \"improperly\", \n",
    "                      \"unacceptable\", \"used\"], axis = 1)\n",
    "matrix.sum().sort_values(ascending = False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat with test data\n",
    "\n",
    "violations_test[\"VIOLATIONS\"] = violations_test[\"VIOLATION DESCRIPTION\"].apply(make_lower)\n",
    "violations_test[\"VIOLATIONS\"] = violations_test[\"VIOLATIONS\"].apply(strip_punctuation)\n",
    "violations_test[\"VIOLATIONS\"] = violations_test[\"VIOLATIONS\"].apply(split_text)\n",
    "violations_test[\"CLEAN VIOLATIONS\"] = violations_test[\"VIOLATIONS\"].apply(remove_stop_words)\n",
    "violations_test[\"PROCESSED VIOLATIONS\"] = violations_test[\"CLEAN VIOLATIONS\"].apply(combine_tokens)\n",
    "\n",
    "\n",
    "X2 = vec.fit_transform(violations_test[\"PROCESSED VIOLATIONS\"])\n",
    "matrix2 = pd.DataFrame(X2.toarray(), columns = vec.get_feature_names_out(), \n",
    "                       index = violations_test.index)\n",
    "matrix2 = matrix2.drop([\"food\", \"non\", \"andor\", \"may\", \"properly\", \"improperly\", \n",
    "                        \"unacceptable\", \"used\"], axis = 1)\n",
    "matrix2 = matrix2.iloc[:, (np.where(matrix2.sum() >= 25)[0].tolist())]\n",
    "\n",
    "matrix2.sum().sort_values(ascending = False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e3aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display([x for x in matrix2 if x not in matrix])\n",
    "\n",
    "display([x for x in matrix if x not in matrix2])\n",
    "\n",
    "missing = [x for x in matrix2 if x not in matrix]\n",
    "matrix2 = matrix2.drop(missing, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c8391",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0.001, 10, 10)\n",
    "\n",
    "for alpha in alphas:\n",
    "    nb_text = MultinomialNB(alpha = alpha, fit_prior = True)\n",
    "    nb_text.fit(matrix, y_train[\"GRADE\"])\n",
    "    nb_pred = nb_text.predict(matrix2)\n",
    "    print(\"Alpha = {}, \\n{}\".format(alpha, f1_score(grades, nb_pred, average = \"weighted\")))\n",
    "    \n",
    "best_alpha = 0.25 # or 6.667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a88f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nb_text = MultinomialNB(alpha = best_alpha)\n",
    "best_nb_text.fit(matrix, y_train[\"GRADE\"])\n",
    "best_nb_pred = best_nb_text.predict_proba(matrix2)\n",
    "\n",
    "nb_roc = roc_auc_score(grades, best_nb_pred, multi_class = \"ovr\")\n",
    "nb_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db41fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(\"A\", best_nb_pred)\n",
    "plot_roc_curve(\"B\", best_nb_pred)\n",
    "plot_roc_curve(\"C\", best_nb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da67b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "def show_top10(classifier, vectorizer, categories):\n",
    "    feature_names = vectorizer.columns\n",
    "    #np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(classifier.coef_[i])[-15:]\n",
    "        print(\"{}: {}\".format(category, \" \".join(feature_names[top10])))\n",
    "\n",
    "show_top10(best_nb_text, matrix, y_train.GRADE.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "jhbkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5d44a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA of most common words in classes (can get from nb??)\n",
    "#from gensim.corpora import Dictionary\n",
    "\n",
    "#gensim_dictionary = Dictionary(violations_train[\"CLEAN VIOLATIONS\"])\n",
    "#gensim_dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df722d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gensim_dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
    "corpus = []\n",
    "#for doc in violations_train[\"CLEAN VIOLATIONS\"]:\n",
    "#    corpus.append(gensim_dictionary.doc2bow(doc))\n",
    "\n",
    "#corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.models import LdaModel\n",
    "\n",
    "#NUM_TOPICS = 3\n",
    "#CHUNKSIZE = 2000 \n",
    "#PASSES = 20 # how many times to rerun algorithm to improve\n",
    "#ITERATIONS = 800 # how many times to rerun algorithm to improve\n",
    "\n",
    "# Make an index to word dictionary.\n",
    "#temp = gensim_dictionary[0]  \n",
    "#word_id = gensim_dictionary.id2token\n",
    "\n",
    "#model = LdaModel(\n",
    "    #corpus=corpus,\n",
    "    #id2word=word_id,\n",
    "    #chunksize=CHUNKSIZE,\n",
    "    #alpha='auto',\n",
    "    #eta='auto',\n",
    "    #iterations=ITERATIONS,\n",
    "    #num_topics=NUM_TOPICS,\n",
    "    #passes=PASSES,\n",
    "#)\n",
    "\n",
    "#list_of_topic_tables = []\n",
    "#for topic in model.show_topics(\n",
    "    #num_topics=-1, num_words=10, formatted=False\n",
    "#):\n",
    "    #list_of_topic_tables.append(\n",
    "        #pd.DataFrame(\n",
    "            #topic[1],\n",
    "            #columns=[\"Word\" + \"_\" + str(topic[0]), \"Prob\" + \"_\" + str(topic[0])],\n",
    "        #)\n",
    "    #)\n",
    "#list_of_topic_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d55c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "slnds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3cdbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop([\"VIOLATION DESCRIPTION\"], axis = 1)\n",
    "X_test = X_test.drop([\"VIOLATION DESCRIPTION\"], axis = 1)\n",
    "X_train\n",
    "# go back and drop Record & Grade Date\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb78af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['BORO', 'CUISINE DESCRIPTION','INSPECTION TYPE', 'INSPECTION PURPOSE']\n",
    "X_train = pd.get_dummies(X_train, columns = cols)\n",
    "X_test = pd.get_dummies(X_test, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe436eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ffc0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c0991c",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "Key Assumption - data is linearly separable\n",
    "This means that there is a clear boundary between the different classes in the data. \n",
    "\n",
    "Another assumption - data is normalized. \n",
    "This means that the input features are scaled to have a mean of zero and a standard deviation of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06696984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling vs normalizing\n",
    "\n",
    "cols = [\"Latitude\", \"Longitude\", \"CRITICAL FLAGS PER INSPECTION\", \"MONTHS OPERATING\", \n",
    "        \"TOTAL INSPECTIONS\", \"VIOLATIONS PER INSPECTION\"]\n",
    "\n",
    "for col in cols:\n",
    "    sns.histplot(X_train[col])\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ab4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X_train.select_dtypes(include = [\"float64\", \"int64\"])\\\n",
    ".drop([\"POST COVID\", \"RISKY BUSINESS\"], axis = 1)\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(num_cols)\n",
    "scaled_violations = pd.DataFrame(scaled_features, index = num_cols.index, \n",
    "                                 columns = num_cols.columns)\n",
    "scaled_violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_cols = X_train.drop(num_cols, axis = 1)\n",
    "other_cols = other_cols.drop(\"VIOLATION DESCRIPTION\", axis = 1)\n",
    "other_cols = pd.get_dummies(other_cols)\n",
    "clean_violations = other_cols.merge(scaled_violations, right_index = True, left_index = True)\n",
    "\n",
    "\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "#scaled_features_test = X_test.select_dtypes(include = [\"float64\", \"int64\"])\\\n",
    "#.drop([\"POST COVID\", \"RISKY BUSINESS\"], axis = 1)\n",
    "\n",
    "#clean_violations_test = make_pipeline(scaled_features_test)\n",
    "#clean_violations_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd1522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0.1, 10, 15)\n",
    "clean_violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32901f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':np.linspace(0.1, 10, 5), 'gamma':['scale', 'auto'], \n",
    "              'class_weight':[None, 'balanced', {'A':1, 'B':3, 'C':3}], \n",
    "              'kernel':['linear', 'rbf', 'poly']}\n",
    "svc = SVC(probability = True, random_state = SEED)\n",
    "best_svc = GridSearchCV(svc, parameters, cv = kfold)\n",
    "best_svc.fit(X_train_sub, y_train[\"GRADE\"])\n",
    "best_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "knkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0741bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC\n",
    "\n",
    "#reg_params = np.linspace(0.1, 10, 3)\n",
    "#gammas = [\"scale\", \"auto\"]\n",
    "#class_weights = [None, \"balanced\"]\n",
    "\n",
    "#for param in reg_params:\n",
    "    #for gamma in gammas:\n",
    "        #for weight in class_weights:\n",
    "            #svc = SVC(C = param, gamma = gamma, class_weight = weight, probability = True, \n",
    "                      #random_state = SEED)\n",
    "            #svc.fit(clean_violations, y_train[\"GRADE\"])\n",
    "            #svc_pred = svc.predict(X_test)\n",
    "            #svc_pred = svc.predict_proba(X_test)\n",
    "            #print(\"Weight = {}, Gamma = {}, C = {}, \\n{}\".format(weight, gamma, param,\n",
    "                                                                 #classification_report(grades, \n",
    "                                                                                       #svc_pred, \n",
    "                                                                                       #zero_division = 0.)))\n",
    "            \n",
    "# zero_division\n",
    "#svc_auc = roc_auc_score(grades, best_svc_pred, multi_class = \"ovr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# penalized SVM uses C != 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5f4966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d7ba1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
